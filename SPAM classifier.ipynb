{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPAM Classifier\n",
    "A simple program which could be used to label a SMS a Ham or Spam based upon the importance of word used in the SMS itself.\n",
    "\n",
    "We use Spam.csv file which can be found on internet or at the address of \"D:/Acadview training notes/spam.csv\"\n",
    "\n",
    "Main python - library used are:\n",
    "\n",
    "numpy\n",
    "\n",
    "pandas\n",
    "\n",
    "sklearn.feature_extraction.text\n",
    "\n",
    "StratifiedShuffleSplit\n",
    " and various other classification machine models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the spam.csv file. We use encoding latin1 such that SMS could be read by UTF \n",
    "\n",
    "createDataset method takes the filepath as input to the spam.csv file and returns the X column containing the SMS and y column containing the labels to those messages(i.e. Ham or Spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createDataset(filePath):\n",
    "    df = pd.read_csv(filePath,encoding=\"latin1\")\n",
    "    df.head()\n",
    "    X=pd.DataFrame(df[\"SMS\"])\n",
    "    y=pd.DataFrame(df[\"class\"])\n",
    "    y = y.values.reshape(5572)\n",
    "    print(np.sum(df[\"class\"]=='spam'))\n",
    "    print(np.sum(df[\"class\"]=='ham'))\n",
    "    return X,y,df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "747\n",
      "4825\n"
     ]
    }
   ],
   "source": [
    "filePath = \"D:/Acadview training notes/spam.csv\"\n",
    "X,y,df = createDataset(filePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using TF - IDF for feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We vectorize the SMS columns such that the string could be made easier to extract features. Basically vectorizing the sms column help us to make more and more features to our data. \n",
    " \n",
    " TF - IDF vectorizer extracts feature based upon the frequency and importance of the word. That is the reason of including it to classify the sms using the important words featured with the help of TF - IDF vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize():\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    textFeatures=df['SMS']\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    #FX_train \n",
    "    fX= vectorizer.fit_transform(textFeatures)\n",
    "    #FX_test = vectorizer.fit_transform(X_test)\n",
    "    return fX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fX = vectorize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stratified Shuffle split is a cross-validation method of combination of StratifiedK fold and ShuffleSplit. In the spam dataset we clearly observe that number of spam are less than the ham sms, so in that case spliting of dataset into training and testing dataset should be stratified such that the ratio of the spam and ham label are balanced, hence we use the stratified shuffled split it maintains the percentage of label for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the data set using Stratified Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "def spliter(fX,y):\n",
    "    s = StratifiedShuffleSplit(n_splits=2, test_size=0.5, random_state=7)\n",
    "    s.get_n_splits(fX,y)\n",
    "    \n",
    "    for train_index, test_index in s.split(fX, y):\n",
    "        print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = fX[train_index], fX[test_index]\n",
    "        y_train, y_test = y[[train_index]], y[[test_index]]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [2230 5530 2234 ..., 3325 3899 1588] TEST: [5139 3271 5013 ..., 2774 1670 1685]\n",
      "TRAIN: [1407  942  175 ..., 1590 2529 5560] TEST: [2241 1679 2228 ..., 5484 5408 3383]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = spliter(fX,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "def model_accuracy(y_true,pred):\n",
    "    print(\"1) Accuracy score = \",metrics.accuracy_score(y_true,pred)*100,\"%\")\n",
    "    print(\"2) Confusion matrix : \\n\",confusion_matrix(y_true,pred))\n",
    "    print(\"3) Classification report : \\n\",classification_report(y_true,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = MultinomialNB(alpha=0.22)\n",
    "model.fit(X_train,y_train)\n",
    "fX.shape\n",
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Accuracy score =  98.1694185212 %\n",
      "2) Confusion matrix : \n",
      " [[2403    9]\n",
      " [  42  332]]\n",
      "3) Classification report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.98      1.00      0.99      2412\n",
      "       spam       0.97      0.89      0.93       374\n",
      "\n",
      "avg / total       0.98      0.98      0.98      2786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_accuracy(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374\n",
      "2412\n"
     ]
    }
   ],
   "source": [
    "modelg = GaussianNB()\n",
    "type(X_train)\n",
    "print(np.sum(y_test=='spam'))\n",
    "print(np.sum(y_test=='ham'))\n",
    "modelg.fit(X_train.todense(),y_train)\n",
    "pred1 = modelg.predict(X_test.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Accuracy score =  90.5240488155 %\n",
      "2) Confusion matrix : \n",
      " [[2183  229]\n",
      " [  35  339]]\n",
      "3) Classification report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.98      0.91      0.94      2412\n",
      "       spam       0.60      0.91      0.72       374\n",
      "\n",
      "avg / total       0.93      0.91      0.91      2786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_accuracy(y_test,pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelb = BernoulliNB()\n",
    "modelb.fit(X_train,y_train)\n",
    "pred2 = modelb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Accuracy score =  97.1643933955 %\n",
      "2) Confusion matrix : \n",
      " [[2409    3]\n",
      " [  76  298]]\n",
      "3) Classification report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.97      1.00      0.98      2412\n",
      "       spam       0.99      0.80      0.88       374\n",
      "\n",
      "avg / total       0.97      0.97      0.97      2786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_accuracy(y_test,pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svc = SVC(C=10000)\n",
    "svc.fit(X_train,y_train)\n",
    "pred3 = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Accuracy score =  98.3129935391 %\n",
      "2) Confusion matrix : \n",
      " [[2408    4]\n",
      " [  43  331]]\n",
      "3) Classification report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.98      1.00      0.99      2412\n",
      "       spam       0.99      0.89      0.93       374\n",
      "\n",
      "avg / total       0.98      0.98      0.98      2786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_accuracy(y_test,pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(criterion='gini')\n",
    "dtc.fit(X_train,y_train)\n",
    "pred4 = dtc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Accuracy score =  96.4106245513 %\n",
      "2) Confusion matrix : \n",
      " [[2362   50]\n",
      " [  50  324]]\n",
      "3) Classification report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.98      0.98      0.98      2412\n",
      "       spam       0.87      0.87      0.87       374\n",
      "\n",
      "avg / total       0.96      0.96      0.96      2786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_accuracy(y_test,pred4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bgg = BaggingClassifier(base_estimator=mnb,n_estimators=120,random_state=7)\n",
    "bgg.fit(X_train,y_train)\n",
    "pre = bgg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Accuracy score =  94.2928930366 %\n",
      "2) Confusion matrix : \n",
      " [[2412    0]\n",
      " [ 159  215]]\n",
      "3) Classification report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.94      1.00      0.97      2412\n",
      "       spam       1.00      0.57      0.73       374\n",
      "\n",
      "avg / total       0.95      0.94      0.94      2786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_accuracy(y_test,pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=20,algorithm='brute')\n",
    "knn.fit(X_train,y_train)\n",
    "pree = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Accuracy score =  95.5132806892 %\n",
      "2) Confusion matrix : \n",
      " [[2411    1]\n",
      " [ 124  250]]\n",
      "3) Classification report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.95      1.00      0.97      2412\n",
      "       spam       1.00      0.67      0.80       374\n",
      "\n",
      "avg / total       0.96      0.96      0.95      2786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_accuracy(y_test,pree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LR = LogisticRegression()\n",
    "LR.fit(X_train,y_train)\n",
    "predd = LR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Accuracy score =  94.472361809 %\n",
      "2) Confusion matrix : \n",
      " [[2409    3]\n",
      " [ 151  223]]\n",
      "3) Classification report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.94      1.00      0.97      2412\n",
      "       spam       0.99      0.60      0.74       374\n",
      "\n",
      "avg / total       0.95      0.94      0.94      2786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_accuracy(y_test,predd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
