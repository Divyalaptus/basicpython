{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = pd.DataFrame(data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "x = StandardScaler().fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 55)\n",
    "x_std = pca.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.914214</td>\n",
       "      <td>-0.954502</td>\n",
       "      <td>-3.946035</td>\n",
       "      <td>2.028723</td>\n",
       "      <td>-0.267173</td>\n",
       "      <td>0.530327</td>\n",
       "      <td>-1.415321</td>\n",
       "      <td>1.496062</td>\n",
       "      <td>0.124914</td>\n",
       "      <td>-0.822246</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.147594</td>\n",
       "      <td>0.100290</td>\n",
       "      <td>0.420029</td>\n",
       "      <td>-0.179378</td>\n",
       "      <td>0.154212</td>\n",
       "      <td>0.470459</td>\n",
       "      <td>0.128759</td>\n",
       "      <td>-0.108361</td>\n",
       "      <td>0.017914</td>\n",
       "      <td>0.217284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.588980</td>\n",
       "      <td>0.924636</td>\n",
       "      <td>3.924755</td>\n",
       "      <td>-1.779850</td>\n",
       "      <td>-0.993430</td>\n",
       "      <td>-0.675652</td>\n",
       "      <td>1.878565</td>\n",
       "      <td>0.556336</td>\n",
       "      <td>1.079877</td>\n",
       "      <td>0.087451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022378</td>\n",
       "      <td>-0.532894</td>\n",
       "      <td>-0.138601</td>\n",
       "      <td>-0.112084</td>\n",
       "      <td>0.764731</td>\n",
       "      <td>0.058997</td>\n",
       "      <td>-0.062811</td>\n",
       "      <td>-0.048471</td>\n",
       "      <td>0.395305</td>\n",
       "      <td>0.005322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.302039</td>\n",
       "      <td>-0.317189</td>\n",
       "      <td>3.023333</td>\n",
       "      <td>-2.043376</td>\n",
       "      <td>-2.081155</td>\n",
       "      <td>0.935121</td>\n",
       "      <td>-1.296200</td>\n",
       "      <td>1.156160</td>\n",
       "      <td>0.785606</td>\n",
       "      <td>-1.099206</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.646057</td>\n",
       "      <td>-0.568704</td>\n",
       "      <td>0.344729</td>\n",
       "      <td>0.180769</td>\n",
       "      <td>0.495403</td>\n",
       "      <td>-0.379882</td>\n",
       "      <td>-0.006784</td>\n",
       "      <td>-0.081455</td>\n",
       "      <td>0.310967</td>\n",
       "      <td>0.178624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.020770</td>\n",
       "      <td>-0.868772</td>\n",
       "      <td>-0.801744</td>\n",
       "      <td>-2.187039</td>\n",
       "      <td>-0.556813</td>\n",
       "      <td>0.727124</td>\n",
       "      <td>0.959766</td>\n",
       "      <td>-1.382638</td>\n",
       "      <td>0.259075</td>\n",
       "      <td>0.744555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430608</td>\n",
       "      <td>-0.184575</td>\n",
       "      <td>0.019432</td>\n",
       "      <td>-0.160415</td>\n",
       "      <td>0.144037</td>\n",
       "      <td>0.339174</td>\n",
       "      <td>0.347814</td>\n",
       "      <td>0.128994</td>\n",
       "      <td>0.759133</td>\n",
       "      <td>-0.115443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.528949</td>\n",
       "      <td>-1.093480</td>\n",
       "      <td>0.973121</td>\n",
       "      <td>-1.419510</td>\n",
       "      <td>-1.715106</td>\n",
       "      <td>1.431592</td>\n",
       "      <td>1.073649</td>\n",
       "      <td>-0.968240</td>\n",
       "      <td>-1.660216</td>\n",
       "      <td>1.174593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.831098</td>\n",
       "      <td>0.853649</td>\n",
       "      <td>-0.345438</td>\n",
       "      <td>0.169067</td>\n",
       "      <td>0.279853</td>\n",
       "      <td>0.227091</td>\n",
       "      <td>0.396234</td>\n",
       "      <td>0.172144</td>\n",
       "      <td>-0.281930</td>\n",
       "      <td>-0.335099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  1.914214 -0.954502 -3.946035  2.028723 -0.267173  0.530327 -1.415321   \n",
       "1  0.588980  0.924636  3.924755 -1.779850 -0.993430 -0.675652  1.878565   \n",
       "2  1.302039 -0.317189  3.023333 -2.043376 -2.081155  0.935121 -1.296200   \n",
       "3 -3.020770 -0.868772 -0.801744 -2.187039 -0.556813  0.727124  0.959766   \n",
       "4  4.528949 -1.093480  0.973121 -1.419510 -1.715106  1.431592  1.073649   \n",
       "\n",
       "         7         8         9     ...           45        46        47  \\\n",
       "0  1.496062  0.124914 -0.822246    ...    -0.147594  0.100290  0.420029   \n",
       "1  0.556336  1.079877  0.087451    ...     0.022378 -0.532894 -0.138601   \n",
       "2  1.156160  0.785606 -1.099206    ...    -0.646057 -0.568704  0.344729   \n",
       "3 -1.382638  0.259075  0.744555    ...     0.430608 -0.184575  0.019432   \n",
       "4 -0.968240 -1.660216  1.174593    ...     0.831098  0.853649 -0.345438   \n",
       "\n",
       "         48        49        50        51        52        53        54  \n",
       "0 -0.179378  0.154212  0.470459  0.128759 -0.108361  0.017914  0.217284  \n",
       "1 -0.112084  0.764731  0.058997 -0.062811 -0.048471  0.395305  0.005322  \n",
       "2  0.180769  0.495403 -0.379882 -0.006784 -0.081455  0.310967  0.178624  \n",
       "3 -0.160415  0.144037  0.339174  0.347814  0.128994  0.759133 -0.115443  \n",
       "4  0.169067  0.279853  0.227091  0.396234  0.172144 -0.281930 -0.335099  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data = x_std)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainX, testX, trainy, testy = train_test_split( x_std,y, test_size=0.20,random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.fit(trainX,trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = LR.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94722222222222219"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(pred,testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 38  0  1  0  0  0  0  3  1]\n",
      " [ 0  1 39  0  0  0  0  0  1  0]\n",
      " [ 0  0  0 32  0  0  0  0  3  0]\n",
      " [ 0  0  0  0 36  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 27  0  0  1  2]\n",
      " [ 0  0  0  0  0  0 27  0  0  0]\n",
      " [ 0  0  1  0  0  0  0 33  2  0]\n",
      " [ 0  1  0  1  0  0  1  0 33  0]\n",
      " [ 0  2  0  0  1  1  0  0  0 29]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(pred,testy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        43\n",
      "          1       0.90      0.88      0.89        43\n",
      "          2       0.97      0.95      0.96        41\n",
      "          3       0.94      0.91      0.93        35\n",
      "          4       0.97      1.00      0.99        36\n",
      "          5       0.96      0.90      0.93        30\n",
      "          6       0.96      1.00      0.98        27\n",
      "          7       1.00      0.92      0.96        36\n",
      "          8       0.77      0.92      0.84        36\n",
      "          9       0.91      0.88      0.89        33\n",
      "\n",
      "avg / total       0.94      0.94      0.94       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(pred,testy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99332220367278801"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
